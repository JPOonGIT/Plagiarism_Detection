{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import Doc_import\n",
    "import os\n",
    "import json\n",
    "import Data_Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import Data_Preprocessing\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        kernel = 4\n",
    "        input_ff = int(393216/(kernel * kernel))\n",
    "        zwischenlayer1 = int(1000)\n",
    "        zwischenlayer2 = int(10)\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.pooling = nn.MaxPool2d(kernel)\n",
    "        self.linear11 = nn.Linear(input_ff, zwischenlayer1)\n",
    "        self.linear12 = nn.Linear(zwischenlayer1, zwischenlayer2)\n",
    "        self.linear13 = nn.Linear(zwischenlayer2, 1)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        bert_output = self.bert(**input_data)\n",
    "        bert_output = self.pooling(bert_output[0])\n",
    "        bert_output = bert_output[0].view(-1, 24576)\n",
    "        x1 = F.relu(self.linear11(bert_output))\n",
    "        x1 = F.relu(self.linear12(x1))\n",
    "        x1 = self.linear13(x1)\n",
    "\n",
    "        return x1\n",
    "\n",
    "    def train_x1(self, features, labels, loss_function, optimizer, epochs):\n",
    "        log_interval = 5\n",
    "        for epoch in range(epochs):\n",
    "            for i, data in enumerate(train_features):\n",
    "                data = Data_Preprocessing.preprocessing(data)\n",
    "                optimizer.zero_grad()\n",
    "                output1 = self.forward(data)\n",
    "\n",
    "                loss_x1 = loss_function(output1, torch.tensor(labels[i]['multi-author']))\n",
    "                print(' ist=', output1, ' soll=', torch.tensor(labels[i]['multi-author']), ' Loss=', loss_x1)\n",
    "                loss_x1.backward(retain_graph=True)\n",
    "                optimizer.step()\n",
    "                #if index % log_interval == 0:\n",
    "                 #   print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epochs, index * len(features),\n",
    "                  #                                                                 len(features),\n",
    "                   #                                                                100. * index / len(features),\n",
    "                    #                                                               loss_x1.data.item()))\n",
    "\n",
    "    def test_model(self, features, labels, loss_function):\n",
    "        log_interval = 5\n",
    "        for index, data in enumerate(features):\n",
    "            output = self(data)\n",
    "            loss = loss_function(output, labels[index]['multi-author'])\n",
    "\n",
    "            if index % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(index, index * len(data),\n",
    "                                                                               len(data),\n",
    "                                                                               100. * index / len(data),\n",
    "                                                                               loss.data.item()))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_features, train_labels, test_features, test_labels = Doc_import.import_pan21(base_path=r\"C:\\Users\\jan-p\\Documents\\Uni Wuppertal\\Semester 2\\Information \"\n",
    "                                 r\"Retrival\\Projekt\\Data\\pan21\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#for data in train_features[0:3]:\n",
    " #   print(data ,'\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "C:\\Users\\jan-p\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:96: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ist= tensor([[-0.3892]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(1.3892, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[-0.2074]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(1.2074, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[-0.0363]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(1.0363, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.5139]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.4861, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.8517]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.8517, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.7176]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.7176, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.2642]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.7358, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[-0.0399]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(1.0399, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[-0.1199]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(0.1199, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[-0.0981]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(0.0981, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[-0.0351]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(1.0351, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.0620]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.9380, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.2053]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.7947, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.5949]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.4051, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.6061]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.6061, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.5438]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.5438, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.7616]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.2384, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.6406]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.3594, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9296]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0704, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.6729]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.6729, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.7439]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.7439, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9953]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0047, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0045]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0045, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.6591]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.3409, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.5816]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.4184, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.6494]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(0.6494, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.5715]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.4285, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.7267]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.2733, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.8012]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.1988, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.4587]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.4587, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.4555]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.4555, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.1038]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.1038, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.6930]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.3070, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.5400]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(0.5400, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.4097]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.5903, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.3537]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.6463, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.3369]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.6631, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.3381]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(0.3381, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.3292]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.6708, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.3335]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.6665, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.3468]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.6532, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.3684]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.6316, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.3981]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(0.3981, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.4138]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(0.4138, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.4174]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.5826, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.4309]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.5691, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.4538]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.5462, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.4876]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.5124, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.5363]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.4637, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.6106]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(0.6106, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.6538]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(0.6538, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.6558]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.3442, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.6926]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.3074, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.7760]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.2240, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9323]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(0.9323, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9948]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0052, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.1684]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(1.1684, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.1884]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.1884, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0469]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(1.0469, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.8568]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.1432, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.7852]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.2148, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.7698]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.2302, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.7860]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.2140, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.8328]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.1672, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9140]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0860, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0585]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0585, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.1181]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(1.1181, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0865]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0865, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0005]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0005, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.8973]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(0.8973, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.8071]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.1929, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.7676]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.2324, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.7516]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.2484, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.7503]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.2497, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.7578]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.2422, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.7713]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.2287, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.7897]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.2103, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.8118]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.1882, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.8372]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.1628, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.8652]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.1348, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.8957]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(0.8957, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9179]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0821, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9432]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(0.9432, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9608]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0392, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9819]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0181, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0061]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0061, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0226]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0226, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0322]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0322, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0353]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(1.0353, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0331]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0331, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0258]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0258, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0143]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0143, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9990]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0010, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9904]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0096, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9878]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0122, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9906]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(0.9906, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9881]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0119, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9909]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0091, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9985]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0015, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0103]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0103, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0158]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(1.0158, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0158]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0158, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0108]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(1.0108, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0013]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0013, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9878]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0122, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9806]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0194, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9791]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0209, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9828]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0172, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9911]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0089, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0036]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(1.0036, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0098]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0098, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0104]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0104, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0059]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0059, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9969]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0031, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9938]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0062, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9960]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0040, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0030]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0030, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0043]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0043, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0004]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(1.0004, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9920]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0080, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9894]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(0.9894, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9820]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0180, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9804]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0196, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9839]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0161, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9921]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0079, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0045]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0045, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0106]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0106, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0112]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(1.0112, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0066]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0066, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9976]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0024, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9944]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0056, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9965]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(0.9965, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9935]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0065, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9957]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0043, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0027]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0027, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0040]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(1.0040, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0002]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(1.0002, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9918]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0082, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9892]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0108, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9918]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(0.9918, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9892]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(0.9892, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9819]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(0.9819, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9703]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0297, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9649]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0351, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9650]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0350, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9700]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(0.9700, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9696]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0304, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9742]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0258, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9834]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0166, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9966]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0034, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0136]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0136, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0238]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0238, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0280]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0280, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0268]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0268, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0207]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0207, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0102]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0102, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9958]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0042, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9878]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0122, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9856]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0144, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9886]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0114, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9963]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0037, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0083]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(1.0083, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0140]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0140, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0142]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(1.0142, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0094]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(1.0094, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0000]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(2.8729e-05, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9866]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0134, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9795]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0205, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9782]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0218, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9819]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0181, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9903]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0097, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0029]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0029, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0092]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(1.0092, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0098]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0098, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[1.0054]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(1.0054, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9965]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(0.9965, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9834]], grad_fn=<AddmmBackward0>)  soll= tensor(1)  Loss= tensor(0.0166, grad_fn=<L1LossBackward0>)\n",
      " ist= tensor([[0.9767]], grad_fn=<AddmmBackward0>)  soll= tensor(0)  Loss= tensor(0.9767, grad_fn=<L1LossBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-5-198b704d39bf>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mcriterion\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mL1Loss\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_x1\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_features\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtrain_labels\u001B[0m \u001B[1;33m,\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m<ipython-input-2-2ea2c7b7e0a7>\u001B[0m in \u001B[0;36mtrain_x1\u001B[1;34m(self, features, labels, loss_function, optimizer, epochs)\u001B[0m\n\u001B[0;32m     41\u001B[0m                 \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m' ist='\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutput1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m' soll='\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlabels\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'multi-author'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m' Loss='\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mloss_x1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     42\u001B[0m                 \u001B[0mloss_x1\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mretain_graph\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 43\u001B[1;33m                 \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     44\u001B[0m                 \u001B[1;31m#if index % log_interval == 0:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     45\u001B[0m                  \u001B[1;31m#   print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epochs, index * len(features),\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     86\u001B[0m                 \u001B[0mprofile_name\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"Optimizer.step#{}.step\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__class__\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     87\u001B[0m                 \u001B[1;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprofiler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrecord_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprofile_name\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 88\u001B[1;33m                     \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     89\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     90\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001B[0m in \u001B[0;36mdecorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     25\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclone\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 27\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     28\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mcast\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mF\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\sgd.py\u001B[0m in \u001B[0;36mstep\u001B[1;34m(self, closure)\u001B[0m\n\u001B[0;32m    142\u001B[0m                         \u001B[0mmomentum_buffer_list\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstate\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'momentum_buffer'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    143\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 144\u001B[1;33m             F.sgd(params_with_grad,\n\u001B[0m\u001B[0;32m    145\u001B[0m                   \u001B[0md_p_list\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    146\u001B[0m                   \u001B[0mmomentum_buffer_list\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\_functional.py\u001B[0m in \u001B[0;36msgd\u001B[1;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001B[0m\n\u001B[0;32m    192\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    193\u001B[0m         \u001B[0malpha\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlr\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mmaximize\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;33m-\u001B[0m\u001B[0mlr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 194\u001B[1;33m         \u001B[0mparam\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0md_p\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0malpha\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0malpha\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    195\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    196\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9)\n",
    "criterion = nn.L1Loss()\n",
    "model.train()\n",
    "model.train_x1(train_features,train_labels , criterion, optimizer, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}